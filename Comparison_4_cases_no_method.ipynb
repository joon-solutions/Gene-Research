{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, plot_roc_curve, roc_curve  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV, GridSearchCV, permutation_test_score\n",
    "from sklearn import metrics\n",
    "from scipy.stats import randint\n",
    "import time\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NCBI_ID' 'KEGG Gene ID' 'Max group mean' 'Log₂ fold change'\n",
      " 'Fold change' 'P-value' 'FDR p-value' 'Bonferroni' 'Group']\n",
      "Total length of df :  412\n",
      "no missed values\n",
      "(412, 9)\n",
      "(411, 9)\n",
      "length of df1 :  411\n"
     ]
    }
   ],
   "source": [
    "# Read U1_T1 data\n",
    "cols1 = [2, 3, 8, 9, 10, 11, 12, 13, 14] \n",
    "df1 = pd.read_excel (r'C:\\Users\\nguye\\joon_first_test\\original_data\\U1_vs_T1 original.xlsx', sheet_name='Sheet1',usecols=cols1) #,skiprows=3)\n",
    "features1 = df1.columns.values\n",
    "print(features1)\n",
    "#print(df1[features[1]])\n",
    "\n",
    "print('Total length of df : ',len(df1))\n",
    "# check present of missing values in whole df\n",
    "if (df1.isnull().any().any()): \n",
    "    print('remove rows with missing values')\n",
    "    tot_null_val1 = [pd.isna(df1[features1[0]]).sum(axis=0), pd.isna(df1[features1[1]]).sum(axis=0),\n",
    "                    pd.isna(df1[features1[2]]).sum(axis=0), pd.isna(df1[features1[3]]).sum(axis=0),\n",
    "                    pd.isna(df1[features1[4]]).sum(axis=0), pd.isna(df1[features1[5]]).sum(axis=0),\n",
    "                    pd.isna(df1[features1[6]]).sum(axis=0), pd.isna(df1[features1[7]]).sum(axis=0)]\n",
    "#    print(tot_null_val)\n",
    "    index_feat1 = []\n",
    "    for i in range(0, len(tot_null_val1)):\n",
    "        if tot_null_val1[i] != 0: index_feat1.append(i)\n",
    "#    print(type(index_feat))\n",
    "    \n",
    "    for j in range(len(index_feat1)):\n",
    "        feat_process1 = features1[(index_feat1[j])]\n",
    "#        print(feat_process)    \n",
    "        ind_remove1 = np.where(df1[feat_process1].isnull())[0]\n",
    "#        print(ind_remove)\n",
    "        for k in range(0,len(ind_remove1)):\n",
    "            df1 = df1.drop(ind_remove1[k], axis=0)\n",
    "    print('length of df1 : ',len(df1))    \n",
    "\n",
    "else: print('no missed values')\n",
    "    \n",
    "print(df1.shape) \n",
    "\n",
    "# removal of dulicates and not available values\n",
    "df1 = df1.drop_duplicates(features1[0], keep=\"last\")\n",
    "index_name11 = df1[ df1[features1[0]] == '-' ].index\n",
    "df1.drop(index_name11, inplace = True, axis=0)\n",
    "\n",
    "print(df1.shape) \n",
    "#df1.index = np.arange(0,len(df1))\n",
    "print('length of df1 : ',len(df1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of df2 :  513\n",
      "no missed values\n",
      "(513, 9)\n"
     ]
    }
   ],
   "source": [
    "# Read U20_T76 data\n",
    "cols2 = [2, 3, 8, 9, 10, 11, 12, 13, 14] \n",
    "df2 = pd.read_excel (r'C:\\Users\\nguye\\joon_first_test\\original_data\\U20_vs_T76 original.xlsx', sheet_name='U20_vs_T76',usecols=cols2) #,skiprows=3)\n",
    "features2 = df2.columns.values\n",
    "print('Total length of df2 : ',len(df2))\n",
    "\n",
    " # check present of missing values in whole df\n",
    "if (df2.isnull().any().any()):\n",
    "    print('remove rows with missing values')\n",
    "    tot_null_val2 = [pd.isna(df2[features2[0]]).sum(axis=0), pd.isna(df2[features2[1]]).sum(axis=0),\n",
    "                    pd.isna(df2[features2[2]]).sum(axis=0), pd.isna(df2[features2[3]]).sum(axis=0),\n",
    "                    pd.isna(df2[features2[4]]).sum(axis=0), pd.isna(df2[features2[5]]).sum(axis=0),\n",
    "                    pd.isna(df2[features2[6]]).sum(axis=0), pd.isna(df2[features2[7]]).sum(axis=0)]\n",
    "#    print(tot_null_val)\n",
    "    index_feat2 = []\n",
    "    for i in range(0, len(tot_null_val)):\n",
    "        if tot_null_val2[i] != 0: index_feat.append(i)\n",
    "#    print(type(index_feat))\n",
    "    \n",
    "    for j in range(len(index_feat2)):\n",
    "        feat_process2 = features2[(index_feat2[j])]\n",
    "#        print(feat_process)    \n",
    "        ind_remove2 = np.where(df2[feat_process2].isnull())[0]\n",
    "#        print(ind_remove)\n",
    "        for k in range(0,len(ind_remove2)):\n",
    "            df2 = df2.drop(ind_remove2[k], axis=0)\n",
    "    print('length of df2 : ',len(df2))    \n",
    "\n",
    "else: print('no missed values')\n",
    "print(df2.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of df3 :  904\n",
      "no missed values\n",
      "(904, 9)\n",
      "length of df2 :  904\n"
     ]
    }
   ],
   "source": [
    "# Read U1_T76 data\n",
    "cols3 = [2, 3, 8, 9, 10, 11, 12, 13, 14] \n",
    "df3 = pd.read_excel (r'C:\\Users\\nguye\\joon_first_test\\original_data\\U1_vs_T76 original.xlsx', sheet_name='Sheet1',usecols=cols3) #,skiprows=3)\n",
    "print('Total length of df3 : ',len(df3))\n",
    "features3 = df3.columns.values\n",
    "# check present of missing values in whole df\n",
    "if (df3.isnull().any().any()):\n",
    "    print('remove rows with missing values')\n",
    "    tot_null_val3 = [pd.isna(df3[features3[0]]).sum(axis=0), pd.isna(df3[features3[1]]).sum(axis=0),\n",
    "                    pd.isna(df3[features3[2]]).sum(axis=0), pd.isna(df3[features3[3]]).sum(axis=0),\n",
    "                    pd.isna(df3[features3[4]]).sum(axis=0), pd.isna(df3[features3[5]]).sum(axis=0),\n",
    "                    pd.isna(df3[features3[6]]).sum(axis=0), pd.isna(df3[features3[7]]).sum(axis=0)]\n",
    "#    print(tot_null_val)\n",
    "    index_feat3 = []\n",
    "    for i in range(0, len(tot_null_val)):\n",
    "        if tot_null_val3[i] != 0: index_feat3.append(i)\n",
    "#    print(type(index_feat))\n",
    "    \n",
    "    for j in range(len(index_feat)):\n",
    "        feat_process3 = features3[(index_feat3[j])]\n",
    "#        print(feat_process)    \n",
    "        ind_remove3 = np.where(df3[feat_process3].isnull())[0]\n",
    "#        print(ind_remove)\n",
    "        for k in range(0,len(ind_remove3)):\n",
    "            df3 = df3.drop(ind_remove3[k], axis=0)\n",
    "    print('length of df3 : ',len(df3))    \n",
    "\n",
    "else: print('no missed values')\n",
    "    \n",
    "print(df3.shape) \n",
    "print('length of df2 : ',len(df3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of df4 :  1399\n",
      "no missed values\n",
      "(1399, 9)\n",
      "length of df4 :  1399\n"
     ]
    }
   ],
   "source": [
    "# Read U1_U20 data\n",
    "cols4 = [2, 3, 8, 9, 10, 11, 12, 13, 14] \n",
    "df4 = pd.read_excel (r'C:\\Users\\nguye\\joon_first_test\\original_data\\U1_vs_U20 original.xlsx', sheet_name='Sheet1',usecols=cols4) #,skiprows=3)\n",
    "print('Total length of df4 : ',len(df4))\n",
    "features4 = df4.columns.values\n",
    "# check present of missing values in whole df\n",
    "if (df4.isnull().any().any()):\n",
    "    print('remove rows with missing values')\n",
    "    tot_null_val4 = [pd.isna(df4[features4[0]]).sum(axis=0), pd.isna(df4[features4[1]]).sum(axis=0),\n",
    "                    pd.isna(df4[features4[2]]).sum(axis=0), pd.isna(df4[features4[3]]).sum(axis=0),\n",
    "                    pd.isna(df4[features4[4]]).sum(axis=0), pd.isna(df4[features4[5]]).sum(axis=0),\n",
    "                    pd.isna(df4[features4[6]]).sum(axis=0), pd.isna(df4[features4[7]]).sum(axis=0)]\n",
    "#    print(tot_null_val)\n",
    "    index_feat4 = []\n",
    "    for i in range(0, len(tot_null_val4)):\n",
    "        if tot_null_va4l[i] != 0: index_feat4.append(i)\n",
    "#    print(type(index_feat))\n",
    "    \n",
    "    for j in range(len(index_feat)):\n",
    "        feat_process4 = features4[(index_feat4[j])]\n",
    "#        print(feat_process)    \n",
    "        ind_remove4 = np.where(df4[feat_process4].isnull())[0]\n",
    "#        print(ind_remove)\n",
    "        for k in range(0,len(ind_remove4)):\n",
    "            df4 = df4.drop(ind_remove4[k], axis=0)\n",
    "    print('length of df4 : ',len(df4))    \n",
    "\n",
    "else: print('no missed values')\n",
    "    \n",
    "print(df4.shape) \n",
    "print('length of df4 : ',len(df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of upregulated genes :  215\n",
      "length of downregulated genes :  196\n",
      "(411, 9)\n"
     ]
    }
   ],
   "source": [
    "# Divide df1 into upregulated and downregulated subset of genes \n",
    "# upregulated genes have group of T1, downregulated genes have group of U1\n",
    "# Gen A has fold change >= 0.5 and P-value <= 0.05 <==> upregulated, otherwise <==> downregulated\n",
    "\n",
    "upregulated_df1 = df1.loc[df1[features1[8]] == 'T1'].reset_index(drop=True)\n",
    "print('length of upregulated genes : ',len(upregulated_df1))\n",
    "\n",
    "#ptdf = df1.loc[df1[features1[4]] >= 0.5]\n",
    "#print(ptdf.shape)\n",
    "#ptdf = ptdf.loc[ptdf[features1[5]] < 0.05].reset_index(drop=True)\n",
    "#print(ptdf.shape)\n",
    "\n",
    "downregulated_df1 = df1.loc[df1[features1[8]] == 'U1'].reset_index(drop=True)\n",
    "print('length of downregulated genes : ',len(downregulated_df1))\n",
    "\n",
    "selected_df1 = upregulated_df1.append(downregulated_df1)\n",
    "print(selected_df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 2)\n",
      "49\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# U1_vs_T1 genes upregulated will present in U20_vs_T76\n",
    "t1 = len(upregulated_df1)\n",
    "A1 = pd.DataFrame(columns = features1)\n",
    "A2 = pd.DataFrame(columns = features2)\n",
    "A3 = pd.DataFrame(columns = ['status1'])\n",
    "string11 = pd.DataFrame({'status1':['avail']})\n",
    "string12 = pd.DataFrame({'status1':['not_avail']})\n",
    "for i in range(t1):\n",
    "    string1 = upregulated_df1.iloc[i, 0] \n",
    "    findings1 = df2['NCBI_ID'].str.contains(string1)\n",
    "    total1 = findings1.sum() \n",
    "    if(total1 > 0): \n",
    "        A1 = A1.append(upregulated_df1.iloc[i,:], ignore_index=True)\n",
    "        A3 = A3.append(string11)\n",
    "        for j in range(len(findings1)):\n",
    "            if (findings1[j] == True):\n",
    "                A2 = A2.append(df2.iloc[j,:], ignore_index=True)\n",
    "    else: A3 = A3.append(string12)\n",
    "if not A1.empty:\n",
    "    A3['U20_T76'] = A2.iloc[:,8]\n",
    "    A3 = A3[['U20_T76', 'status1']]\n",
    "    A3 = A3.reset_index(drop = True)\n",
    "else: print('There is no gene of first condition available on second condition. Should be re-test')\n",
    "print(A3.shape)\n",
    "\n",
    "# Removal of not available genes\n",
    "index_not_avail_A = A3[ A3['status1'] == 'not_avail' ].index\n",
    "A3.drop(index_not_avail_A, inplace = True, axis=0)\n",
    "A3 = A3.reset_index(drop = True)\n",
    "upregulated_df1.drop(index_not_avail_A, inplace = True, axis=0)\n",
    "upregulated_df1 = upregulated_df1.reset_index(drop = True)\n",
    "print(len(A3))\n",
    "print(len(upregulated_df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 2)\n",
      "48\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# U1_vs_T1 genes downregulated will present in U20_vs_T76\n",
    "dt1 = len(downregulated_df1)\n",
    "dA1 = pd.DataFrame(columns = features1)\n",
    "dA2 = pd.DataFrame(columns = features2)\n",
    "dA3 = pd.DataFrame(columns = ['status1'])\n",
    "dstring11 = pd.DataFrame({'status1':['avail']})\n",
    "dstring12 = pd.DataFrame({'status1':['not_avail']})\n",
    "for i in range(dt1):\n",
    "    dstring1 = downregulated_df1.iloc[i, 0] \n",
    "    dfindings1 = df2['NCBI_ID'].str.contains(dstring1)\n",
    "    dtotal1 = dfindings1.sum() \n",
    "    if(dtotal1 > 0): \n",
    "        dA1 = dA1.append(downregulated_df1.iloc[i,:], ignore_index=True)\n",
    "        dA3 = dA3.append(dstring11)\n",
    "        for j in range(len(dfindings1)):\n",
    "            if (dfindings1[j] == True):\n",
    "                dA2 = dA2.append(df2.iloc[j,:], ignore_index=True)\n",
    "    else: dA3 = dA3.append(dstring12)\n",
    "if not dA1.empty:\n",
    "    dA3['U20_T76'] = dA2.iloc[:,8]\n",
    "    dA3 = dA3[['U20_T76', 'status1']]\n",
    "    dA3 = dA3.reset_index(drop = True)\n",
    "else: print('There is no gene of first condition available on second condition. Should be re-test')\n",
    "print(dA3.shape)\n",
    "\n",
    "# Removal of not available genes\n",
    "dindex_not_avail_A = dA3[ dA3['status1'] == 'not_avail' ].index\n",
    "dA3.drop(dindex_not_avail_A, inplace = True, axis=0)\n",
    "dA3 = dA3.reset_index(drop = True)\n",
    "downregulated_df1.drop(dindex_not_avail_A, inplace = True, axis=0)\n",
    "downregulated_df1 = downregulated_df1.reset_index(drop = True)\n",
    "print(len(dA3))\n",
    "print(len(downregulated_df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 2)\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# U1_vs_T1 genes upregulated will present in U1-T76\n",
    "t2 = len(upregulated_df1)\n",
    "B1 = pd.DataFrame(columns = features1)\n",
    "B2 = pd.DataFrame(columns = features3)\n",
    "B3 = pd.DataFrame(columns = ['status2'])\n",
    "string21 = pd.DataFrame({'status2':['avail']})\n",
    "string22 = pd.DataFrame({'status2':['not_avail']})\n",
    "for i in range(t2):\n",
    "    string2 = upregulated_df1.iloc[i, 0]  \n",
    "    findings2 = df3['NCBI_ID'].str.contains(string2)\n",
    "    total2 = findings2.sum()\n",
    "    if(total2 > 0): \n",
    "        B1 = B1.append(upregulated_df1.iloc[i,:], ignore_index=True)\n",
    "        B3 = B3.append(string21)\n",
    "        for j in range(len(findings2)):\n",
    "            if (findings2[j] == True):\n",
    "                B2 = B2.append(df3.iloc[j,:], ignore_index=True)\n",
    "    else: B3 = B3.append(string22)\n",
    "if not B1.empty:\n",
    "    B3['U1_T76'] = B2.iloc[:,8]\n",
    "    B3 = B3[['U1_T76', 'status2']]\n",
    "    B3 = B3.reset_index(drop = True)\n",
    "print(B3.shape)\n",
    "\n",
    "# Removal of not available genes\n",
    "index_not_avail_B = B3[ B3['status2'] == 'not_avail' ].index\n",
    "B3.drop(index_not_avail_B, inplace = True, axis=0)\n",
    "B3 = B3.reset_index(drop = True)\n",
    "upregulated_df1.drop(index_not_avail_B, inplace = True, axis=0)\n",
    "upregulated_df1 = upregulated_df1.reset_index(drop = True)\n",
    "print(len(B3))\n",
    "print(len(upregulated_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 2)\n",
      "31\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# U1_vs_T1 genes downregulated will present in U1-T76 condition\n",
    "dt2 = len(downregulated_df1)\n",
    "dB1 = pd.DataFrame(columns = features1)\n",
    "dB2 = pd.DataFrame(columns = features3)\n",
    "dB3 = pd.DataFrame(columns = ['status2'])\n",
    "dstring21 = pd.DataFrame({'status2':['avail']})\n",
    "dstring22 = pd.DataFrame({'status2':['not_avail']})\n",
    "for i in range(dt2):\n",
    "    dstring2 = downregulated_df1.iloc[i, 0]  \n",
    "    dfindings2 = df3['NCBI_ID'].str.contains(dstring2)\n",
    "    dtotal2 = dfindings2.sum()\n",
    "    if(dtotal2 > 0): \n",
    "        dB1 = dB1.append(downregulated_df1.iloc[i,:], ignore_index=True)\n",
    "        dB3 = dB3.append(dstring21)\n",
    "        for j in range(len(dfindings2)):\n",
    "            if (dfindings2[j] == True):\n",
    "                dB2 = dB2.append(df3.iloc[j,:], ignore_index=True)\n",
    "    else: dB3 = dB3.append(dstring22)\n",
    "if not dB1.empty:\n",
    "    dB3['U1_T76'] = dB2.iloc[:,8]\n",
    "    dB3 = dB3[['U1_T76', 'status2']]\n",
    "    dB3 = dB3.reset_index(drop = True)\n",
    "print(dB3.shape)\n",
    "\n",
    "# Removal of not available genes\n",
    "dindex_not_avail_B = dB3[ dB3['status2'] == 'not_avail' ].index\n",
    "dB3.drop(dindex_not_avail_B, inplace = True, axis=0)\n",
    "dB3 = dB3.reset_index(drop = True)\n",
    "downregulated_df1.drop(dindex_not_avail_B, inplace = True, axis=0)\n",
    "downregulated_df1 = downregulated_df1.reset_index(drop = True)\n",
    "print(len(dB3))\n",
    "print(len(downregulated_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 2)\n",
      "13\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# U1_vs_T1 genes upregulated will present in U1-U20\n",
    "t3 = len(upregulated_df1)\n",
    "C1 = pd.DataFrame(columns = features1)\n",
    "C2 = pd.DataFrame(columns = features4)\n",
    "C3 = pd.DataFrame(columns = ['status3'])\n",
    "string31 = pd.DataFrame({'status3':['avail']})\n",
    "string32 = pd.DataFrame({'status3':['not_avail']})\n",
    "for i in range(t3):\n",
    "    string3 = upregulated_df1.iloc[i, 0] \n",
    "    findings3 = df4['NCBI_ID'].str.contains(string3)\n",
    "    total3 = findings3.sum() \n",
    "    if(total3 > 0): \n",
    "        C1 = C1.append(upregulated_df1.iloc[i,:], ignore_index=True)\n",
    "        C3 = C3.append(string31)\n",
    "        for j in range(len(findings3)):\n",
    "            if (findings3[j] == True):\n",
    "                C2 = C2.append(df4.iloc[j,:], ignore_index=True)\n",
    "    else: C3 = C3.append(string32)\n",
    "if not C1.empty:\n",
    "    C3['U1_U20'] = C2.iloc[:,8]\n",
    "    C3 = C3[['U1_U20', 'status3']] \n",
    "    C3 = C3.reset_index(drop = True)\n",
    "print(C3.shape)\n",
    "\n",
    "# Removal of not available genes\n",
    "index_not_avail_C = C3[ C3['status3'] == 'not_avail' ].index\n",
    "C3.drop(index_not_avail_C, inplace = True, axis=0)\n",
    "C3 = C3.reset_index(drop = True)\n",
    "upregulated_df1.drop(index_not_avail_C, inplace = True, axis=0)\n",
    "upregulated_df1 = upregulated_df1.reset_index(drop = True)\n",
    "print(len(C3))\n",
    "print(len(upregulated_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no downregulated gene in U1-T1 is existed in U1-U20\n"
     ]
    }
   ],
   "source": [
    "# U1_vs_T1 genes downregulated will present in U1-U20\n",
    "dt3 = len(downregulated_df1)\n",
    "dC1 = pd.DataFrame(columns = features1)\n",
    "dC2 = pd.DataFrame(columns = features4)\n",
    "dC3 = pd.DataFrame(columns = ['status3'])\n",
    "dstring31 = pd.DataFrame({'status3':['avail']})\n",
    "dstring32 = pd.DataFrame({'status3':['not_avail']})\n",
    "for i in range(dt3):\n",
    "    dstring3 = downregulated_df1.iloc[i, 0] \n",
    "    dfindings3 = df4['NCBI_ID'].str.contains(string3)\n",
    "    dtotal3 = dfindings3.sum() \n",
    "    if(dtotal3 > 0): \n",
    "        dC1 = dC1.append(downregulated_df1.iloc[i,:], ignore_index=True)\n",
    "        dC3 = dC3.append(dstring31)\n",
    "        for j in range(len(dfindings3)):\n",
    "            if (dfindings3[j] == True):\n",
    "                dC2 = dC2.append(df4.iloc[j,:], ignore_index=True)\n",
    "    else: dC3 = dC3.append(dstring32)\n",
    "if not dC1.empty:\n",
    "    dC3['U1_U20'] = dC2.iloc[:,8]\n",
    "    dC3 = dC3[['U1_U20', 'status3']] \n",
    "    dC3 = dC3.reset_index(drop = True)\n",
    "    print(dC3.shape)\n",
    "    # Removal of not available genes\n",
    "    dindex_not_avail_C = dC3[ dC3['status3'] == 'not_avail' ].index\n",
    "    dC3.drop(dindex_not_avail_C, inplace = True, axis=0)\n",
    "    dC3 = dC3.reset_index(drop = True)\n",
    "    downregulated_df1.drop(dindex_not_avail_C, inplace = True, axis=0)\n",
    "    downregulated_df1 = downregulated_df1.reset_index(drop = True)\n",
    "    print(len(dC3))\n",
    "    print(downregulated_df1)\n",
    "else: print('no downregulated gene in U1-T1 is existed in U1-U20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 16)\n"
     ]
    }
   ],
   "source": [
    "# Transcriptional changes of selected genes\n",
    "# The first task is to select which genes in U1-T1 are present in others conditions\n",
    "# If a gene in U1_T1 is not available in one of 3 conditions, then that gene is not considered for further processing\n",
    "\n",
    "D1 = pd.DataFrame(columns = ['stat1'])\n",
    "D2 = pd.DataFrame(columns = ['stat2'])\n",
    "D3 = pd.DataFrame(columns = ['stat3'])\n",
    "state11 = pd.DataFrame({'stat1':['yes-upregulated']})\n",
    "state12 = pd.DataFrame({'stat1':['no-downregulated']})\n",
    "state21 = pd.DataFrame({'stat2':['yes-upregulated']})\n",
    "state22 = pd.DataFrame({'stat2':['no-downregulated']})\n",
    "state31 = pd.DataFrame({'stat3':['yes-upregulated']})\n",
    "state32 = pd.DataFrame({'stat3':['no-downregulated']})\n",
    "\n",
    "D = pd.DataFrame(columns = ['decision'])\n",
    "string41 = pd.DataFrame({'decision':['MOA-related or process-related']})\n",
    "string42 = pd.DataFrame({'decision':['MOA-related']})\n",
    "string43 = pd.DataFrame({'decision':['MOA-related, but effect is age-dependent']})\n",
    "string44 = pd.DataFrame({'decision':['no conclusion']})\n",
    "\n",
    "upregulated_df1.loc[:,'U20_T76'] = A3['U20_T76']\n",
    "upregulated_df1.loc[:,'U1_T76'] = B3['U1_T76']\n",
    "upregulated_df1.loc[:,'U1_U20'] = C3['U1_U20']\n",
    "\n",
    "t4 = len(upregulated_df1)   \n",
    "for i in range(t4):\n",
    "    string51 = upregulated_df1.iloc[i, 9]\n",
    "    if (string51 == 'T76'): \n",
    "        D1 = D1.append(state11)\n",
    "        string52 = upregulated_df1.iloc[i,10]\n",
    "        if (string52 == 'T76'):\n",
    "            D2 = D2.append(state21)\n",
    "            string53 = upregulated_df1.iloc[i,11]\n",
    "            if (string53 == 'U20'):\n",
    "                D = D.append(string41)\n",
    "                D3 = D3.append(state31)\n",
    "            else: # string53 == 'U1'\\\n",
    "                D = D.append(string42)\n",
    "                D3 = D3.append(state32)\n",
    "        else: #(string52 == 'U1'):\n",
    "            D2 = D2.append(state22)\n",
    "            string53 = upregulated_df1.iloc[i,11]\n",
    "            if (string53 == 'U1'):\n",
    "                D = D.append(string43)\n",
    "                D3 = D3.append(state32)\n",
    "            else: # string53 == 'U20'\n",
    "                D = D.append(string44) \n",
    "                D3 = D3.append(state32)\n",
    "    else:#(string51 == 'U20'): \n",
    "        D1 = D1.append(state12)\n",
    "        string52 = upregulated_df1.iloc[i,10]        \n",
    "        if (string52 == 'T76'):\n",
    "            D2 = D2.append(state21)\n",
    "            string53 = upregulated_df1.iloc[i,11]\n",
    "            if (string53 == 'U1'):\n",
    "                D = D.append(string43)\n",
    "                D3 = D3.append(state32)\n",
    "            else: # string53 == 'U20'\\\n",
    "                D = D.append(string44)\n",
    "                D3 = D3.append(state32)\n",
    "        else: #(string52 == 'U1'):\n",
    "            D2 = D2.append(state22)\n",
    "            string53 = upregulated_df1.iloc[i,11]\n",
    "            if (string53 == 'U1'):\n",
    "                D = D.append(string43)\n",
    "                D3 = D3.append(state32)\n",
    "            else: # string53 == 'U20'\n",
    "                D = D.append(string44) \n",
    "                D3 = D3.append(state32)    \n",
    "#print(upregulated_df1)\n",
    "D = D.reset_index(drop = True)\n",
    "D1 = D1.reset_index(drop = True)\n",
    "D2 = D2.reset_index(drop = True)\n",
    "D3 = D3.reset_index(drop = True)\n",
    "upregulated_df1.loc[:,'stat1'] = D1['stat1']\n",
    "upregulated_df1.loc[:,'stat2'] = D2['stat2']\n",
    "upregulated_df1.loc[:,'stat3'] = D3['stat3']\n",
    "upregulated_df1.loc[:,'decision'] = D['decision']\n",
    "upregulated_df1 = upregulated_df1[['NCBI_ID','KEGG Gene ID','Max group mean','Log₂ fold change','Fold change','P-value','FDR p-value',\n",
    "                'Bonferroni','Group','stat1','U20_T76','stat2','U1_T76','stat3','U1_U20','decision']]\n",
    "\n",
    "#index_nothing = upregulated_df1[ upregulated_df1['decision'] == 'nothing'].index\n",
    "#upregulated_df1.drop(index_nothing, inplace = True, axis=0)\n",
    "#upregulated_df1 = upregulated_df1.reset_index(drop = True)\n",
    "print(upregulated_df1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to excel file\n",
    "writer = pd.ExcelWriter('transcriptional_change_4_cases.xlsx', engine='xlsxwriter')\n",
    "selected_df1.to_excel(writer, sheet_name='up_down_processed_gene_U1_T1')\n",
    "upregulated_df1.to_excel(writer, sheet_name='upregulated_gene')\n",
    "writer.save()\n",
    "#selected_df1.to_excel(r'C:\\Users\\nguye\\joon_first_test\\selected_genes_M3_noMethod\\transcriptional_change_4_cases_no_method.xlsx', sheet_name='up_down_processed_gene_U1_T1', index = True)\n",
    "#upregulated_df1.to_excel(r'C:\\Users\\nguye\\joon_first_test\\selected_genes_M3_noMethod\\transcriptional_change_4_cases_no_method.xlsx', sheet_name='upregulated_gene', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upregulated_df1.style.apply(lambda x: ['background-color: orange']*upregulated_df1.shape[1] \n",
    "#                                  if (x.impact == 'effect is probably due to treatment' or x.impact == 'effect might be due to treatment')\n",
    "#                                  else['']*upregulated_df1.shape[1], axis=1)\n",
    "#\n",
    "# Export to excel file\n",
    "#upregulated_df1.style.apply(lambda x: ['background-color: orange']*upregulated_df1.shape[1] \n",
    "#                                  if (x.impact == 'effect is probably due to treatment' or x.impact == 'effect might be due to treatment')\n",
    "#                                  else['']*upregulated_df1.shape[1], axis=1).to_excel(r'C:\\Users\\nguye\\joon_first_test\\selected_genes_M3_noMethod\\transcriptional_change_4_cases_no_method.xlsx', sheet_name='Sheet1', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
